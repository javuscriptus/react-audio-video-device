import { Ref, RefObject, useEffect, useRef, useState } from 'react';

import { useSettingsStore } from '@/store/store';

// Renamed the variable after your comment.
var peerConnection = new RTCPeerConnection({
  iceServers: [],
});

const useDevices = () => {
  let localStream = null;

  const settingsStore = useSettingsStore((state) => state);

  const { audioinput, audiooutput, videoinput, handleVolume } = settingsStore;
  console.log('üöÄ ‚û°Ô∏è file: useDevices.tsx:9 ‚û°Ô∏è useDevices ‚û°Ô∏è audioinput', {
    audioinput,
    audiooutput,
    videoinput,
  });

  const localAudioRef = useRef<RefObject<HTMLAudioElement>>();
  const remoteAudioRef = useRef<RefObject<HTMLAudioElement>>();
  const videoElemRef = useRef<RefObject<HTMLAudioElement>>();

  const audioInputRef = useRef<HTMLSelectElement>();
  const audioOutputRef = useRef<HTMLSelectElement>();
  const videoInputRef = useRef<HTMLSelectElement>();

  const audioInputRangeRef = useRef<any>();
  const audioOutputRangeRef = useRef<any>();
  const videoInputRangeRef = useRef<any>();

  const audioInputCurrentSelect = audioInputRef.current as any;
  const audioOutputCurrentSelect = audioOutputRef.current as any;
  const videoInputCurrentSelect = videoInputRef.current as any;

  const [isRerender, setIsRerender] = useState(false);
  const [options, setOptions] = useState<any>([]);

  const selectors = [
    audioInputCurrentSelect,
    audioOutputCurrentSelect,
    videoInputCurrentSelect,
  ];
  console.log('üöÄ ‚û°Ô∏è file: useDevices.tsx:32 ‚û°Ô∏è useDevices ‚û°Ô∏è selectors', [
    selectors,
    audioInputCurrentSelect?.volume,
  ]);
  const rangeElements = [audioInputRangeRef, audioOutputRangeRef, videoInputRangeRef];

  function getDevices(deviceInfos: any) {
    if (options.length) {
      return;
    }

    for (let i = 0; i !== deviceInfos.length; ++i) {
      const deviceInfo = deviceInfos[i];

      if (deviceInfo.kind === 'audioinput') {
        setOptions((prev: any) => [
          ...prev,
          {
            kind: 'audioinput',
            value: deviceInfo.deviceId,
            label: deviceInfo.label,
          },
        ]);
      } else if (deviceInfo.kind === 'audiooutput') {
        setOptions((prev: any) => [
          ...prev,
          {
            kind: 'audiooutput',
            value: deviceInfo.deviceId,
            label: deviceInfo.label,
          },
        ]);
      } else if (deviceInfo.kind === 'videoinput') {
        setOptions((prev: any) => [
          ...prev,
          {
            kind: 'videoinput',
            value: deviceInfo.deviceId,
            label: deviceInfo.label,
          },
        ]);
      } else {
        console.log('Some other kind of source/device: ', deviceInfo);
      }
    }

    start();
  }

  function gotStream(stream: any) {
    // –ü–æ–ª—É—á–∞–µ–º –≤–∏–¥–µ–æ–¥–æ—Ä–æ–∂–∫—É –∏–∑ –ø–æ—Ç–æ–∫–∞ (stream)
    const videoTracks = stream.getVideoTracks();
    console.log('üöÄ ‚û°Ô∏è file: useDevices.tsx:98 ‚û°Ô∏è gotStream ‚û°Ô∏è videoTracks', videoTracks);

    /**
     * Create a new audio context and build a stream source,
     * stream destination and a gain node. Pass the stream into
     * the mediaStreamSource so we can use it in the Web Audio API.
     * ==================
     * –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –∞—É–¥–∏–æ–∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Å–æ–∑–¥–∞–µ–º source –ø–æ—Ç–æ–∫,
     * –∫–æ–Ω–µ—á–Ω–æ–µ –º–µ—Å—Ç–æ –ø–æ—Ç–æ–∫–∞ –∏ GAIN —É–∑–µ–ª. –ü–µ—Ä–µ–¥–∞–µ–º –ø–æ—Ç–æ–∫ –≤
     * source MediaStreamSource, —á—Ç–æ–±—ã –º—ã –º–æ–≥–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ Web Audio API.
     */
    const context = new AudioContext();
    console.log('üöÄ ‚û°Ô∏è file: useDevices.tsx:110 ‚û°Ô∏è gotStream ‚û°Ô∏è context', context);
    const mediaStreamSource = context.createMediaStreamSource(stream);
    console.log(
      'üöÄ ‚û°Ô∏è file: useDevices.tsx:112 ‚û°Ô∏è gotStream ‚û°Ô∏è mediaStreamSource',
      mediaStreamSource,
    );
    const mediaStreamDestination = context.createMediaStreamDestination();
    console.log(
      'üöÄ ‚û°Ô∏è file: useDevices.tsx:114 ‚û°Ô∏è gotStream ‚û°Ô∏è mediaStreamDestination',
      mediaStreamDestination,
    );
    const gainNode = context.createGain();
    console.log('üöÄ ‚û°Ô∏è file: useDevices.tsx:116 ‚û°Ô∏è gotStream ‚û°Ô∏è gainNode', gainNode);

    /**
     * Connect the stream to the gainNode so that all audio
     * passes through the gain and can be controlled by it.
     * Then pass the stream from the gain to the mediaStreamDestination
     * which can pass it back to the RTC client.
     * ===================
     * –ü–æ–¥–∫–ª—é—á–∏—Ç–µ –ø–æ—Ç–æ–∫ –∫ GAIN —É–∑–ª—É, —á—Ç–æ–±—ã –≤—Å–µ –∞—É–¥–∏–æ
     * –ø—Ä–æ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ GAIN –∏ –æ–Ω —Å–º–æ–≥ —É–ø—Ä–∞–≤–ª—è—Ç—å –∑–≤—É–∫–æ–º.
     * –ó–∞—Ç–µ–º –ø–µ—Ä–µ–¥–∞–µ–º –ø–æ—Ç–æ–∫ –∏–∑ GAIN –≤ mediaStreamDestination
     * –∫–æ—Ç–æ—Ä—ã–π –≤ —Å–≤–æ—é –æ—á–µ—Ä–µ–¥—å –æ—Å—É—â–µ—Å—Ç–≤–∏—Ç –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç—É RTC.
     */
    mediaStreamSource.connect(gainNode);
    gainNode.connect(mediaStreamDestination);

    /**
     * Change the gain levels on the input selector.
     * ===================
     * –ò–∑–º–µ–Ω—è–µ–º —É—Ä–æ–≤–Ω–∏ –∑–≤—É–∫–∞ –æ–±—Ä–∞—â–∞—è—Å—å –∫ —ç—Ç–æ–π —Ñ—É–Ω–∫—Ü–∏–∏.
     */
    const changeValue = (event) => {
      gainNode.gain.value = event.target.value;
    };

    /**
     * The mediaStreamDestination.stream outputs a MediaStream object
     * containing a single AudioMediaStreamTrack. Add the video track
     * to the new stream to rejoin the video with the controlled audio.
     * ==================
     * mediaStreamDestination.stream –≤—ã–≤–æ–¥–∏—Ç –æ–±—ä–µ–∫—Ç MediaStream
     * —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –æ–¥–Ω—É –¥–æ—Ä–æ–∂–∫—É –∞—É–¥–∏–æ–º–µ–¥–∏–∞–ø–æ—Ç–æ–∫–∞. –î–æ–±–∞–≤–ª—è–µ–º –≤–∏–¥–µ–æ–¥–æ—Ä–æ–∂–∫—É
     * –∫ –Ω–æ–≤–æ–º—É –ø–æ—Ç–æ–∫—É, —á—Ç–æ–±—ã –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—ã–π –∑–≤—É–∫ —Å –≤–∏–¥–µ–æ.
     */
    const controlledStream = mediaStreamDestination.stream;

    for (const videoTrack of videoTracks) {
      controlledStream.addTrack(videoTrack);
    }

    /**
     * Use the stream that went through the gainNode. This
     * is the same stream but with altered input volume levels.
     * ==================
     * –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ç–æ–∫, –ø—Ä–æ—à–µ–¥—à–∏–π —á–µ—Ä–µ–∑ GainNode.
     * –≠—Ç–æ, –ø–æ —Å—É—Ç–∏, —Ç–æ—Ç –∂–µ –ø–æ—Ç–æ–∫, –Ω–æ —Å –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–º —É—Ä–æ–≤–Ω–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç–∏ –≤—Ö–æ–¥–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞.
     */

    videoElemRef.current.srcObject = controlledStream;
    localStream = controlledStream;
    peerConnection.addStream(controlledStream);

    // window.stream = stream;

    // videoElemRef.current.srcObject = stream;

    console.log('.........', navigator.mediaDevices.enumerateDevices());

    return navigator.mediaDevices.enumerateDevices();
  }

  function start() {
    if (window.stream) {
      window.stream.getTracks().forEach((track) => {
        track.stop();
      });
    }

    console.log(window.stream);
    let audioS;
    let videoS;

    setTimeout(() => {
      audioS = audioInputCurrentSelect?.value;
      videoS = videoInputCurrentSelect?.value;

      const constraints = {
        audio: { deviceId: audioS ? { exact: audioS } : undefined },
        video: { deviceId: videoS ? { exact: videoS } : undefined },
      };

      navigator.mediaDevices
        .getUserMedia(constraints)
        .then(gotStream)
        .then(getDevices)
        .catch((err) => console.log('–û—à–∏–±–∫–∞', err));
    }, 3000);
  }

  function attachSinkId(element: any, sinkId: any) {
    if (typeof element.sinkId !== 'undefined') {
      element
        .setSinkId(sinkId)
        .then(() => {
          console.log(`Success, audio output device attached: ${sinkId}`);
        })
        .catch((error: any) => {
          let errorMessage = error;
          if (error.name === 'SecurityError') {
            errorMessage = `You need to use HTTPS for selecting audio output device: ${error}`;
          }
          console.error(errorMessage);

          audioOutputCurrentSelect.selectedIndex = 0;
        });
    } else {
      console.warn('Browser does not support output device selection.');
    }
  }

  function changeAudioDestination() {
    const audioDestination = audioOutputCurrentSelect.value;

    attachSinkId(videoInputCurrentSelect, audioDestination);
  }

  const handleVolumeElement = () => {};

  useEffect(() => {
    navigator.mediaDevices
      .enumerateDevices()
      .then(getDevices)
      .catch((err) => console.log(err));
  }, [videoInputRef, audioOutputRef, videoInputRef]);

  return {
    options: options.reduce((r: any, a: any) => {
      console.log(r);
      r[a.kind] = r[a.kind] || [];
      r[a.kind].push(a);
      return r;
    }, []),
    videoInputRef,
    audioOutputRef,
    audioInputRef,
    audioInputRangeRef,
    audioOutputRangeRef,
    videoInputRangeRef,
    localAudioRef,
    remoteAudioRef,
    videoElemRef,
    start,
    changeAudioDestination,
  };
};

export default useDevices;
